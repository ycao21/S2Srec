{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a832cece",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58565882-6ce6-43ab-91c5-304ae11f2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7da83b6-19ea-42c8-a1e8-a28ba3507f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dc623b3-f956-4cde-a7fa-9914f0195335",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d56bb2bf-4a6f-44ff-a26a-cbc71948cb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class trainDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        # print(X, y)\n",
    "        return torch.LongTensor(X), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5965018b-5012-414c-bd13-6d8e0b914843",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dee0eb99-c00e-4ef6-8ad5-1a6442ac274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.feedforward_clf = nn.Sequential(\n",
    "            nn.Linear(768, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.sigmoid(self.feedforward_clf(x))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5af23ec9-6da0-477a-92be-3694cbd0b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dl, model, criterion, optimizer, epoch):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, (X, y) in enumerate(train_dl):\n",
    "        y_hat = model(X.float()).squeeze(1)\n",
    "        loss = criterion(y_hat.float(), y.float())\n",
    "\n",
    "        losses.update(loss.data, X.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(' Epoch: {ep}\\t'\n",
    "          ' Loss {loss.avg:.5f}\\t'.format(ep=epoch, loss=losses))\n",
    "\n",
    "    return loss.cpu().data.numpy()\n",
    "\n",
    "\n",
    "def test_metrics(test_dl, model):\n",
    "    model.eval()\n",
    "    TPs = 0\n",
    "    predPs = 0.00001\n",
    "    actualPs = 0.00001\n",
    "    losses = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    \n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for i, (X, y) in enumerate(train_dl):\n",
    "        y_hat = model(X.float()).squeeze(1)\n",
    "\n",
    "        loss_func = nn.BCELoss()\n",
    "        loss = loss_func(y_hat.float(), y.float())\n",
    "\n",
    "        clf_binary = y_hat.data.cpu().numpy() > 0.5\n",
    "        correct = (clf_binary == y.data.cpu().numpy()).sum()\n",
    "        accuracy = correct / clf_binary.shape[0]\n",
    "\n",
    "        for i in range(len(y)):\n",
    "            if y[i] == 1:\n",
    "                actualPs += 1\n",
    "                if y_hat[i] > 0.5:\n",
    "                    predPs += 1\n",
    "                    TPs += 1\n",
    "            elif y_hat[i] > 0.5:\n",
    "                predPs += 1\n",
    "\n",
    "        losses.update(loss.data, X.size(0))\n",
    "        accuracies.update(accuracy, X.size(0))\n",
    "\n",
    "    return losses, accuracies, TPs/predPs, TPs/actualPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7da0f0d-268b-43d7-bc58-0272abd15b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(triplet_train_set_path, 'rb') as f:\n",
    "    train_set = pickle.load(f)\n",
    "# with open(triplet_test_set_path, 'rb') as f:\n",
    "#     test_set = pickle.load(f)\n",
    "\n",
    "with open(clf_test_set_path, 'rb') as f:\n",
    "    clf_test_set = pickle.load(f)\n",
    "    \n",
    "with open(ingred_emb_path, 'rb') as f:\n",
    "    ingred_emb = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8792bf3-82ed-47c7-bde9-9a439603f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(train_set)\n",
    "train_recipe_cart_data = [[[e[0]+e[1], 1], [e[0]+e[2], 0]] for i, e in enumerate(train_set[:round(0.7*n)]) if i % 3 == 0]\n",
    "# valid_recipe_cart_data = [[[e[0]+e[1], 1], [e[0]+e[2], 0]] for i, e in enumerate(train_set[round(0.7*n):]) if i % 3 == 0]\n",
    "# test_recipe_cart_data = [[[e[0]+e[1], 1], [e[0]+e[2], 0]] for i, e in enumerate(test_set) if i % 3 == 0]\n",
    "test_recipe_cart_data = clf_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e6128a2-8f0e-41fa-af10-0e8488d0514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_train =  [i for ll in train_recipe_cart_data for i in ll]\n",
    "X_train = [i[0] for i in X_y_train]\n",
    "y_train = [i[1] for i in X_y_train]\n",
    "\n",
    "X_emb_train = []\n",
    "for i in X_train:\n",
    "    n = np.zeros(768)\n",
    "    for j in i:\n",
    "        n += ingred_emb[j]\n",
    "    n = n/len(i)\n",
    "    X_emb_train.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a94511-bd02-4a88-a0b7-d961a3c3444d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2892, 10373], [9589, 2588], 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_recipe_cart_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adab8522-0ebb-4828-9536-40991a7a0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_y_test =  [i for ll in test_recipe_cart_data for i in ll]\n",
    "X_y_test = test_recipe_cart_data\n",
    "X_test = [i[0]+i[1] for i in X_y_test]\n",
    "y_test = [i[2] for i in X_y_test]\n",
    "\n",
    "X_emb_test = []\n",
    "for i in X_test:\n",
    "    n = np.zeros(768)\n",
    "    for j in i:\n",
    "        n += ingred_emb[j]\n",
    "    n = n/len(i)\n",
    "    X_emb_test.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8734d754-5a95-4f29-8c19-8b65c866a0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (sigmoid): Sigmoid()\n",
       "  (feedforward_clf): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=400, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=200, out_features=400, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e4dce55-d648-481a-9774-81d8e0739727",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e324999-be4f-4a8d-9ef9-53b2f3641593",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = trainDataset(X_emb_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=2000, shuffle=True)\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "\n",
    "test_ds = trainDataset(X_emb_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=2000, shuffle=True)\n",
    "test_dl = DeviceDataLoader(test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5f46c6e-ca98-44a7-8e8b-7e628cf2e405",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " tensor([1, 0, 1,  ..., 1, 0, 0]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "X_t,y_t = next(iter(train_dl))\n",
    "\n",
    "X_t, y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bce73a21-9417-4646-9583-a07e2208bd10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Start training epoch 0 ===\n",
      " Epoch: 0\t Loss 0.63647\t\n",
      " -> valid loss: 0.60142\t valid acc: 0.67328\t valid prec: 0.77398\t valid recl: 0.48950\t\n",
      "=== Start training epoch 1 ===\n",
      " Epoch: 1\t Loss 0.59664\t\n",
      " -> valid loss: 0.59310\t valid acc: 0.68612\t valid prec: 0.67452\t valid recl: 0.71938\t\n",
      "=== Start training epoch 2 ===\n",
      " Epoch: 2\t Loss 0.59167\t\n",
      " -> valid loss: 0.59038\t valid acc: 0.68777\t valid prec: 0.68143\t valid recl: 0.70525\t\n",
      "=== Start training epoch 3 ===\n",
      " Epoch: 3\t Loss 0.59133\t\n",
      " -> valid loss: 0.59073\t valid acc: 0.68776\t valid prec: 0.68147\t valid recl: 0.70509\t\n",
      "=== Start training epoch 4 ===\n",
      " Epoch: 4\t Loss 0.59127\t\n",
      " -> valid loss: 0.59140\t valid acc: 0.68741\t valid prec: 0.67700\t valid recl: 0.71683\t\n",
      "=== Start training epoch 5 ===\n",
      " Epoch: 5\t Loss 0.59203\t\n",
      " -> valid loss: 0.59245\t valid acc: 0.68578\t valid prec: 0.67035\t valid recl: 0.73104\t\n",
      "=== Start training epoch 6 ===\n",
      " Epoch: 6\t Loss 0.59106\t\n",
      " -> valid loss: 0.59086\t valid acc: 0.68734\t valid prec: 0.68563\t valid recl: 0.69195\t\n",
      "=== Start training epoch 7 ===\n",
      " Epoch: 7\t Loss 0.59060\t\n",
      " -> valid loss: 0.59068\t valid acc: 0.68742\t valid prec: 0.67701\t valid recl: 0.71685\t\n",
      "=== Start training epoch 8 ===\n",
      " Epoch: 8\t Loss 0.59040\t\n",
      " -> valid loss: 0.59106\t valid acc: 0.68734\t valid prec: 0.68563\t valid recl: 0.69195\t\n",
      "=== Start training epoch 9 ===\n",
      " Epoch: 9\t Loss 0.59049\t\n",
      " -> valid loss: 0.58970\t valid acc: 0.68783\t valid prec: 0.68147\t valid recl: 0.70537\t\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print('=== Start training epoch {} ==='.format(epoch))\n",
    "    loss = train(train_dl, model, criterion, optimizer, epoch)\n",
    "\n",
    "    val_loss, val_acc, val_prec, val_recl = test_metrics(test_dl, model)\n",
    "    print(' -> valid loss: {loss:.5f}\\t'\n",
    "          ' valid acc: {acc:.5f}\\t'\n",
    "          ' valid prec: {prec:.5f}\\t'\n",
    "          ' valid recl: {recl:.5f}\\t'.format(loss=val_loss.avg, acc=val_acc.avg, prec=val_prec, recl=val_recl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2de46d-2c72-497d-85a6-81cbf630b824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6888497139497579"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*0.68562*0.69211)/(0.68562+0.69211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8afa13d-0ae9-4a92-8db9-923c03744fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9310fb-87d8-49de-ac94-5b22dd6fd555",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = clf.predict(X_emb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0411d486-bbec-4f00-b725-ca44c012c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = sum((np.array(y_hat_test) == np.array(y_test))&(np.array(y_test) ==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23935de-4018-4d8b-b5fb-6303280aab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predPs = sum(np.array(y_hat_test) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a7016-bdf0-482a-8dd3-8345befe3ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "actualPs = sum(np.array(y_test) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca329cd-8756-414b-8262-01fc46d424d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = TP/predPs\n",
    "recall = TP/actualPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930e05a-3cd3-4fb5-9166-b1a36402fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceaee6f-24eb-4551-a477-f0756a2cfd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
