{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a832cece",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58565882-6ce6-43ab-91c5-304ae11f2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7da83b6-19ea-42c8-a1e8-a28ba3507f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dc623b3-f956-4cde-a7fa-9914f0195335",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d56bb2bf-4a6f-44ff-a26a-cbc71948cb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class trainDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        # print(X, y)\n",
    "        return torch.LongTensor(X), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5965018b-5012-414c-bd13-6d8e0b914843",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dee0eb99-c00e-4ef6-8ad5-1a6442ac274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.feedforward_clf = nn.Sequential(\n",
    "            nn.Linear(768, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.sigmoid(self.feedforward_clf(x))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5af23ec9-6da0-477a-92be-3694cbd0b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dl, model, criterion, optimizer, epoch):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, (X, y) in enumerate(train_dl):\n",
    "        y_hat = model(X.float()).squeeze(1)\n",
    "        loss = criterion(y_hat.float(), y.float())\n",
    "\n",
    "        losses.update(loss.data, X.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(' Epoch: {ep}\\t'\n",
    "          ' Loss {loss.avg:.5f}\\t'.format(ep=epoch, loss=losses))\n",
    "\n",
    "    return loss.cpu().data.numpy()\n",
    "\n",
    "\n",
    "def test_metrics(test_dl, model):\n",
    "    model.eval()\n",
    "    TPs = 0\n",
    "    FPs = 0\n",
    "    FNs = 0\n",
    "    losses = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    \n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for i, (X, y) in enumerate(train_dl):\n",
    "        y_hat = model(X.float()).squeeze(1)\n",
    "\n",
    "        loss_func = nn.BCELoss()\n",
    "        loss = loss_func(y_hat.float(), y.float())\n",
    "\n",
    "        clf_binary = y_hat.data.cpu().numpy() > 0.5\n",
    "        correct = (clf_binary == y.data.cpu().numpy()).sum()\n",
    "        accuracy = correct / clf_binary.shape[0]\n",
    "\n",
    "        for i in range(len(y)):\n",
    "            if y[i] == 1:\n",
    "                if y_hat[i] > 0.5:\n",
    "                    TPs += 1\n",
    "                else:\n",
    "                    FNs += 1\n",
    "            elif y_hat[i] > 0.5:\n",
    "                FPs += 1\n",
    "\n",
    "        losses.update(loss.data, X.size(0))\n",
    "        accuracies.update(accuracy, X.size(0))\n",
    "\n",
    "    return losses, accuracies, TPs, FPs, FNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7da0f0d-268b-43d7-bc58-0272abd15b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(triplet_train_set_path, 'rb') as f:\n",
    "    train_set = pickle.load(f)\n",
    "# with open(triplet_test_set_path, 'rb') as f:\n",
    "#     test_set = pickle.load(f)\n",
    "\n",
    "with open(clf_test_set_path, 'rb') as f:\n",
    "    clf_test_set = pickle.load(f)\n",
    "    \n",
    "with open(ingred_emb_path, 'rb') as f:\n",
    "    ingred_emb = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8792bf3-82ed-47c7-bde9-9a439603f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(train_set)\n",
    "train_recipe_cart_data = [[[e[0]+e[1], 1], [e[0]+e[2], 0]] for i, e in enumerate(train_set[:round(0.7*n)]) if i % 3 == 0]\n",
    "# valid_recipe_cart_data = [[[e[0]+e[1], 1], [e[0]+e[2], 0]] for i, e in enumerate(train_set[round(0.7*n):]) if i % 3 == 0]\n",
    "test_recipe_cart_data = [[[e[0]+e[1], 1], [e[0]+e[2], 0]] for i, e in enumerate(test_set) if i % 3 == 0]\n",
    "# test_recipe_cart_data = clf_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e6128a2-8f0e-41fa-af10-0e8488d0514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_train =  [i for ll in train_recipe_cart_data for i in ll]\n",
    "X_train = [i[0] for i in X_y_train]\n",
    "y_train = [i[1] for i in X_y_train]\n",
    "\n",
    "X_emb_train = []\n",
    "for i in X_train:\n",
    "    n = np.zeros(768)\n",
    "    for j in i:\n",
    "        n += ingred_emb[j]\n",
    "    n = n/len(i)\n",
    "    X_emb_train.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a94511-bd02-4a88-a0b7-d961a3c3444d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2892, 10373], [9589, 2588], 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_recipe_cart_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adab8522-0ebb-4828-9536-40991a7a0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_test =  [i for ll in test_recipe_cart_data for i in ll]\n",
    "# X_y_test = test_recipe_cart_data\n",
    "X_test = [i[0]+i[1] for i in X_y_test]\n",
    "y_test = [i[2] for i in X_y_test]\n",
    "\n",
    "X_emb_test = []\n",
    "for i in X_test:\n",
    "    n = np.zeros(768)\n",
    "    for j in i:\n",
    "        n += ingred_emb[j]\n",
    "    n = n/len(i)\n",
    "    X_emb_test.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8734d754-5a95-4f29-8c19-8b65c866a0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (sigmoid): Sigmoid()\n",
       "  (feedforward_clf): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=400, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=200, out_features=400, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e4dce55-d648-481a-9774-81d8e0739727",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e324999-be4f-4a8d-9ef9-53b2f3641593",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = trainDataset(X_emb_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=2000, shuffle=True)\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "\n",
    "test_ds = trainDataset(X_emb_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=2000, shuffle=True)\n",
    "test_dl = DeviceDataLoader(test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5f46c6e-ca98-44a7-8e8b-7e628cf2e405",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " tensor([1, 0, 1,  ..., 1, 0, 0]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "X_t,y_t = next(iter(train_dl))\n",
    "\n",
    "X_t, y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bce73a21-9417-4646-9583-a07e2208bd10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Start training epoch 0 ===\n",
      " Epoch: 0\t Loss 0.59069\t\n",
      " -> valid loss: 0.58996\t valid acc: 0.68783\t valid prec: 0.68148\t valid recl: 0.70533\t\n",
      "=== Start training epoch 1 ===\n",
      " Epoch: 1\t Loss 0.59053\t\n",
      " -> valid loss: 0.59018\t valid acc: 0.68783\t valid prec: 0.68147\t valid recl: 0.70537\t\n",
      "=== Start training epoch 2 ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=== Start training epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch))\n\u001b[0;32m----> 3\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# val_loss, val_acc, val_prec, val_recl = test_metrics(test_dl, model)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# print(' -> valid loss: {loss:.5f}\\t'\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#       ' valid acc: {acc:.5f}\\t'\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m#       ' valid prec: {prec:.5f}\\t'\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#       ' valid recl: {recl:.5f}\\t'.format(loss=val_loss.avg, acc=val_acc.avg, prec=val_prec, recl=val_recl))\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     val_loss, val_acc, v_TPs, v_FPs, v_FNs \u001b[38;5;241m=\u001b[39m test_metrics(test_dl, model)\n",
      "Cell \u001b[0;32mIn[44], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_dl, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m      2\u001b[0m losses \u001b[38;5;241m=\u001b[39m AverageMeter()\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dl):\n\u001b[1;32m      7\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m model(X\u001b[38;5;241m.\u001b[39mfloat())\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(y_hat\u001b[38;5;241m.\u001b[39mfloat(), y\u001b[38;5;241m.\u001b[39mfloat())\n",
      "Cell \u001b[0;32mIn[20], line 20\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl:\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m to_device(b, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[22], line 13\u001b[0m, in \u001b[0;36mtrainDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my[idx]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# print(X, y)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mLongTensor(X), \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print('=== Start training epoch {} ==='.format(epoch))\n",
    "    loss = train(train_dl, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # val_loss, val_acc, val_prec, val_recl = test_metrics(test_dl, model)\n",
    "    # print(' -> valid loss: {loss:.5f}\\t'\n",
    "    #       ' valid acc: {acc:.5f}\\t'\n",
    "    #       ' valid prec: {prec:.5f}\\t'\n",
    "    #       ' valid recl: {recl:.5f}\\t'.format(loss=val_loss.avg, acc=val_acc.avg, prec=val_prec, recl=val_recl))\n",
    "    \n",
    "    val_loss, val_acc, v_TPs, v_FPs, v_FNs = test_metrics(test_dl, model)\n",
    "    print(' -> valid loss: {loss:.5f}\\t'\n",
    "          ' valid acc: {acc:.5f}\\t'\n",
    "          ' valid prec: {prec:.5f}\\t'\n",
    "          ' valid recl: {recl:.5f}\\t'.format(loss=val_loss.avg, acc=val_acc.avg, prec=v_TPs/(v_TPs+v_FPs), recl=v_TPs/(v_TPs+v_FNs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2de46d-2c72-497d-85a6-81cbf630b824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6888497139497579"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*0.68562*0.69211)/(0.68562+0.69211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8afa13d-0ae9-4a92-8db9-923c03744fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35499"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_TPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9310fb-87d8-49de-ac94-5b22dd6fd555",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = clf.predict(X_emb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0411d486-bbec-4f00-b725-ca44c012c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = sum((np.array(y_hat_test) == np.array(y_test))&(np.array(y_test) ==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23935de-4018-4d8b-b5fb-6303280aab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predPs = sum(np.array(y_hat_test) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a7016-bdf0-482a-8dd3-8345befe3ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "actualPs = sum(np.array(y_test) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca329cd-8756-414b-8262-01fc46d424d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = TP/predPs\n",
    "recall = TP/actualPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930e05a-3cd3-4fb5-9166-b1a36402fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceaee6f-24eb-4551-a477-f0756a2cfd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
